server:
  port: 8888

spring:
  application:
    name: kafkaDemo
  kafka:
    #kafka 集群，以逗号分隔的地址列表
    bootstrap-servers: 192.168.135.132:9092
    #生产者配置
    producer:
      acks: 1
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #默认批次大小
      batch-size: 16384
      # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka,
      #linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
      properties:
        linger:
          ms: 5
      #发生错误时，重试次数
      retries: 0
      # 缓冲区大小 32M
      buffer-memory: 33554432
    #手动提交 （ 相应的enable-auto-commit 需要设置为false）
    # record：每处理一条commit。           batch：每次poll 的时候，批量提交一次。
    # time： 每个ack-time 间隔提交一次。   count：每次达到ack-count 数量提交一次。
    # count_time: ack-time 或者ack-count 满足其中一个就提交一次。
    # manual：listener 负责ack（批量）。
    # manual_immedieate：listener 负责ack，每调用一次，就立即commit。
    listener:
      ack-mode: manual

    #消费者配置
    consumer:
      group-id: test
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #是否自动提交偏移量,true（ auto-commit-interval 需要这个毫秒值）
      enable-auto-commit: false
      #提交延时（接收到消息多少秒之后提交offset）
      auto-commit-interval: 10000
      #一次调用poll()操作时返回的最大记录数
      max-poll-records: 5
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest

    #批量消费 spring.kafka.listener.type = batch
    #批量消费每次最多消费多少条信息 spring.kafka.comsumer.max-poll-records
